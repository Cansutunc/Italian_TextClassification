{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from transformers import BertTokenizer, BertForSequenceClassification, Trainer, TrainingArguments, EvalPrediction\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "import os\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample from dataset:\n",
      "                                                text  label\n",
      "0  contratto di noleggio installazione manutenzio...      0\n",
      "1  impegno spesa per ilnoleggio di apparecchiatur...      0\n",
      "2  servizio di noleggio di manutenzione ordinaria...      0\n",
      "3  il servizio riguarda il noleggio la manutenzio...      0\n",
      "4  procedura di acquisizione fornitura soluzione ...      0\n",
      "Class distribution:\n",
      "label\n",
      "0    75\n",
      "1    57\n",
      "2    51\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Load tokenizer for mBERT\n",
    "tokenizer = BertTokenizer.from_pretrained(\"bert-base-multilingual-cased\")\n",
    "\n",
    "# Tokenization function\n",
    "def tokenize_function(texts):\n",
    "    if isinstance(texts, pd.Series):\n",
    "        texts = texts.fillna(\"\")  # Replace NaN values with empty strings\n",
    "    return tokenizer(list(texts), padding=True, truncation=True, max_length=256, return_tensors=\"pt\")\n",
    "\n",
    "# Load dataset\n",
    "df = pd.read_csv(\"D:/FinetuningBERT-HFT/Final_Augmented_Labeled_Data.csv\")\n",
    "df[\"label\"] = df[\"label\"].astype(int)\n",
    "print(\"Sample from dataset:\")\n",
    "print(df.head())\n",
    "print(\"Class distribution:\")\n",
    "print(df[\"label\"].value_counts())  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load OOD Dataset if file exists\n",
    "ood_file = \"D:/FinetuningBERT-HFT/Extended_Dataset_with_Random_Topics.csv\"\n",
    "if os.path.exists(ood_file):\n",
    "    df_ood = pd.read_csv(ood_file)\n",
    "    if \"text\" in df_ood.columns:\n",
    "        df_ood = df_ood.dropna(subset=[\"text\"])\n",
    "        df_ood[\"label\"] = 3  # Label OOD samples as class 3\n",
    "    else:\n",
    "        raise ValueError(\"OOD dataset must contain a 'text' column.\")\n",
    "else:\n",
    "    ood_texts = [\n",
    "        \"Quantum computing will revolutionize technology.\",\n",
    "        \"The Renaissance was a cultural movement in Europe.\",\n",
    "        \"Climate change is a major concern for future generations.\",\n",
    "        \"Python is a popular programming language for AI.\",\n",
    "        \"Shakespeare's plays are among the most influential works.\",\n",
    "    ]\n",
    "    df_ood = pd.DataFrame({\"text\": ood_texts, \"label\": [3] * len(ood_texts)})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge datasets\n",
    "df_combined = pd.concat([df, df_ood], ignore_index=True)\n",
    "\n",
    "# Prepare data for training and validation\n",
    "def prepare_data():\n",
    "    train_texts, val_texts, train_labels, val_labels = train_test_split(\n",
    "        df_combined[\"text\"].astype(str).tolist(),\n",
    "        df_combined[\"label\"].tolist(),\n",
    "        test_size=0.2,\n",
    "        stratify=df_combined[\"label\"],\n",
    "        random_state=42\n",
    "    )\n",
    "    return train_texts, val_texts, train_labels, val_labels\n",
    "\n",
    "train_texts, val_texts, train_labels, val_labels = prepare_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dataset Wrapper\n",
    "class DatasetWrapper(Dataset):\n",
    "    def __init__(self, encodings, labels):\n",
    "        self.encodings = encodings\n",
    "        self.labels = labels\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        item = {key: val[idx] for key, val in self.encodings.items()}\n",
    "        item[\"labels\"] = torch.tensor(self.labels[idx], dtype=torch.long)\n",
    "        return item\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.labels)\n",
    "\n",
    "# Create tokenized datasets\n",
    "def create_dataset(texts, labels):\n",
    "    encodings = tokenize_function(texts)\n",
    "    return DatasetWrapper(encodings, labels)\n",
    "\n",
    "train_dataset = create_dataset(train_texts, train_labels)\n",
    "val_dataset = create_dataset(val_texts, val_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-multilingual-cased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "# Load mBERT model\n",
    "def load_model():\n",
    "    return BertForSequenceClassification.from_pretrained(\"bert-base-multilingual-cased\", num_labels=4).to(\"cuda\")\n",
    "\n",
    "model = load_model()\n",
    "\n",
    "# Compute evaluation metrics\n",
    "def compute_metrics(eval_pred: EvalPrediction):\n",
    "    predictions = np.argmax(eval_pred.predictions, axis=1)\n",
    "    labels = eval_pred.label_ids\n",
    "    accuracy = np.mean(predictions == labels)\n",
    "    print(f\"Validation Accuracy: {accuracy:.4f}\")\n",
    "    return {\"accuracy\": accuracy}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training function\n",
    "def train_model():\n",
    "    training_args = TrainingArguments(\n",
    "        output_dir=\"./results\",\n",
    "        evaluation_strategy=\"epoch\",\n",
    "        save_strategy=\"epoch\",\n",
    "        per_device_train_batch_size=8,\n",
    "        per_device_eval_batch_size=8,\n",
    "        num_train_epochs=5,\n",
    "        learning_rate=2e-5,\n",
    "        weight_decay=0.01,\n",
    "        logging_dir=\"./logs\",\n",
    "        load_best_model_at_end=True,\n",
    "    )\n",
    "    \n",
    "    trainer = Trainer(\n",
    "        model=model,\n",
    "        args=training_args,\n",
    "        train_dataset=train_dataset,\n",
    "        eval_dataset=val_dataset,\n",
    "        compute_metrics=compute_metrics\n",
    "    )\n",
    "    \n",
    "    trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Energy-based OOD detection\n",
    "def energy_score(logits):\n",
    "    return -torch.logsumexp(logits, dim=1)\n",
    "\n",
    "# Prediction with energy and confidence thresholds\n",
    "def predict_with_energy(text, threshold=-3.5, confidence_threshold=0.75):\n",
    "    inputs = tokenizer(text, return_tensors=\"pt\", padding=True, truncation=True, max_length=256)\n",
    "    inputs = {key: value.to(\"cuda\") for key, value in inputs.items()}\n",
    "\n",
    "    with torch.no_grad():\n",
    "        outputs = model(**inputs)\n",
    "\n",
    "    softmax_scores = F.softmax(outputs.logits, dim=1)\n",
    "    max_confidence = torch.max(softmax_scores).item()\n",
    "\n",
    "    if max_confidence < confidence_threshold:\n",
    "        return \"Unknown\", -1.0  # Reject low-confidence predictions\n",
    "\n",
    "    score = energy_score(outputs.logits).item()\n",
    "    predicted_class = torch.argmax(outputs.logits, dim=1).item()\n",
    "\n",
    "    if score > threshold or predicted_class == 3:\n",
    "        return \"Unknown\", score\n",
    "    \n",
    "    return predicted_class, score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\pytorch_env\\lib\\site-packages\\transformers\\training_args.py:1575: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of ðŸ¤— Transformers. Use `eval_strategy` instead\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='570' max='570' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [570/570 04:10, Epoch 5/5]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.021440</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.015633</td>\n",
       "      <td>0.995595</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.022121</td>\n",
       "      <td>0.995595</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.021701</td>\n",
       "      <td>0.995595</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.059100</td>\n",
       "      <td>0.020785</td>\n",
       "      <td>0.995595</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Accuracy: 1.0000\n",
      "Validation Accuracy: 0.9956\n",
      "Validation Accuracy: 0.9956\n",
      "Validation Accuracy: 0.9956\n",
      "Validation Accuracy: 0.9956\n"
     ]
    }
   ],
   "source": [
    "# Train the model\n",
    "train_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Text: servizio di manutenzione degli impianti siti al parco idroscalo di condizionamento e riscaldamento e assunzione della figura di terzo responsabile per il triennio 20232025 nan\n",
      "Predicted Class: 0\n",
      "Confidence Score: -4.067328453063965\n",
      "\n",
      "Text: Quantum mechanics describes subatomic particles.\n",
      "Predicted Class: Unknown\n",
      "Confidence Score: -2.3810746669769287\n",
      "\n",
      "Text: Python programming is widely used in AI.\n",
      "Predicted Class: Unknown\n",
      "Confidence Score: -2.603029251098633\n",
      "\n",
      "Text: Servizio di noleggio a lungo termine di n. 2 auto destinate alla Polizia stradale a servizio delle tratte di Autostrada Pedemontana Lombarda SpA\n",
      "Predicted Class: 0\n",
      "Confidence Score: -3.580868721008301\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Test Pipeline\n",
    "def run_tests():\n",
    "    test_texts = [\n",
    "        \"servizio di manutenzione degli impianti siti al parco idroscalo di condizionamento e riscaldamento e assunzione della figura di terzo responsabile per il triennio 20232025 nan\",\n",
    "        \"Quantum mechanics describes subatomic particles.\",\n",
    "        \"Python programming is widely used in AI.\",\n",
    "        \"Servizio di noleggio a lungo termine di n. 2 auto destinate alla Polizia stradale a servizio delle tratte di Autostrada Pedemontana Lombarda SpA\"\n",
    "    ]\n",
    "    \n",
    "    for text in test_texts:\n",
    "        pred_class, score = predict_with_energy(text)\n",
    "        print(f\"Text: {text}\\nPredicted Class: {pred_class}\\nConfidence Score: {score}\\n\")\n",
    "\n",
    "run_tests()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
